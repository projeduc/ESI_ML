{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutoriel : Generative Adversarial Network (GAN)\n",
    "\n",
    "\n",
    "This tutoriel is based on this one : https://keras.io/examples/generative/conditional_gan/\n",
    "\n",
    "and this one https://www.tensorflow.org/tutorials/generative/dcgan \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import colors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 23:40:13.113511: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-27 23:40:13.113545: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, AvgPool2D, Flatten, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, UpSampling2D, Reshape, GlobalMaxPooling2D, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load MNIST dataset \n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizing the values (min-max normalization)\n",
    "x_train = x_train / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[i].reshape(28, 28)) # recontruct the matrix\n",
    "    plt.gray()\n",
    "    plt.title(\"N: \" + str(y_train[i]))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 3)         30        \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 3)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 2)         26        \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 2)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 392)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 393       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 449\n",
      "Trainable params: 449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 23:40:15.598236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-27 23:40:15.598302: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-27 23:40:15.598335: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kariminf-pc): /proc/driver/nvidia/version does not exist\n",
      "2022-05-27 23:40:15.598944: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        Input((28, 28, 1)),\n",
    "        Conv2D(3, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "#         Dropout(0.3),\n",
    "        Conv2D(2, (2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Flatten(),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 100)               1100      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 5, 5, 4)           0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 12, 12, 5)        325       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12, 12, 5)        20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 12, 12, 5)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 26, 26, 5)        405       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 26, 26, 5)        20        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 26, 26, 5)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        46        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,916\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "code_size = 10\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        Input((code_size,)),\n",
    "        Dense(100),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Reshape((5, 5, 4)),\n",
    "        Conv2DTranspose(5, (4, 4), strides=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "#         UpSampling2D(size=(3, 3), interpolation='nearest'),\n",
    "        Conv2DTranspose(5, (4, 4), strides=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "#         Conv2DTranspose(2, (3, 3), strides=(1, 1)),\n",
    "#         BatchNormalization(),\n",
    "#         LeakyReLU(alpha=0.2),\n",
    "        Conv2DTranspose(1, (3, 3), strides=(1, 1), activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. ConditionalGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class created\n"
     ]
    }
   ],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        # to save the generator's loss\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        # to save the discriminator's loss\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    # redefine the method which defines the optimizer and the loss function\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, X_real):\n",
    "        # Unpack the data.\n",
    "\n",
    "        # Sample random points in the latent space for the generator.\n",
    "        M = tf.shape(X_real)[0]\n",
    "        code_vectors = tf.random.normal(shape=(M, self.latent_dim))\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        X_fake = self.generator(code_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        X = tf.concat(\n",
    "            [X_fake, X_real], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        # \n",
    "        Y = tf.concat(\n",
    "            [tf.zeros((M, 1)), tf.ones((M, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            # apply predictions : Y_pred\n",
    "            Y_pred = self.discriminator(X)\n",
    "            # calculate the loss function\n",
    "            d_loss = self.loss_fn(Y, Y_pred)\n",
    "        # calculate the gradients over the discriminator\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        # Apply them on the discriminator's weights\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        code_vectors = tf.random.normal(shape=(M, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        Y_misleading = tf.ones((M, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            # generate some fake images using the generator\n",
    "            X_fake = self.generator(code_vectors)\n",
    "            # predict their labels using the discriminator\n",
    "            Y_pred = self.discriminator(X_fake)\n",
    "            # calculate the loss of the classification :\n",
    "            # the discriminator must classify all images as real\n",
    "            g_loss = self.loss_fn(Y_misleading, Y_pred)\n",
    "        # calculate the gradients over the generator's weights\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        # Apply the gradients to the generator\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss : save it for ulterior use\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "gan = ConditionalGAN(discriminator=discriminator, generator=generator, latent_dim=code_size)\n",
    "\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "print('class created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 23:40:16.231451: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 25s 239ms/step - g_loss: 1.4838 - d_loss: 0.4947\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 27s 274ms/step - g_loss: 1.4349 - d_loss: 0.4226\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 27s 274ms/step - g_loss: 1.0311 - d_loss: 0.6029\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 30s 297ms/step - g_loss: 1.0107 - d_loss: 0.7209\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 33s 331ms/step - g_loss: 0.7295 - d_loss: 0.7112\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 28s 278ms/step - g_loss: 0.8212 - d_loss: 0.6392\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 28s 278ms/step - g_loss: 0.7335 - d_loss: 0.6395\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 27s 265ms/step - g_loss: 0.8030 - d_loss: 0.6370\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.8157 - d_loss: 0.6351\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 26s 262ms/step - g_loss: 0.9555 - d_loss: 0.6057\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 29s 292ms/step - g_loss: 0.7432 - d_loss: 0.7716\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 27s 268ms/step - g_loss: 0.8739 - d_loss: 0.6430\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 27s 269ms/step - g_loss: 0.7216 - d_loss: 0.7540\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 26s 262ms/step - g_loss: 0.8273 - d_loss: 0.6461\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 28s 283ms/step - g_loss: 0.8373 - d_loss: 0.6255\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 27s 270ms/step - g_loss: 0.9492 - d_loss: 0.5970\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 27s 266ms/step - g_loss: 1.1170 - d_loss: 0.5954\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 26s 263ms/step - g_loss: 0.9551 - d_loss: 0.6385\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 1.2319 - d_loss: 0.4505\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 0.9780 - d_loss: 0.6117\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 0.9196 - d_loss: 0.6285\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.7043 - d_loss: 0.8588\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 26s 262ms/step - g_loss: 0.9367 - d_loss: 0.6484\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 28s 280ms/step - g_loss: 1.0334 - d_loss: 0.5406\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 28s 276ms/step - g_loss: 0.7589 - d_loss: 0.6799\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 27s 268ms/step - g_loss: 0.8904 - d_loss: 0.6533\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 26s 264ms/step - g_loss: 0.7644 - d_loss: 0.6549\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 0.8648 - d_loss: 0.7052\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 28s 281ms/step - g_loss: 0.7743 - d_loss: 0.6463\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 27s 269ms/step - g_loss: 0.8020 - d_loss: 0.6456\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 27s 270ms/step - g_loss: 0.7396 - d_loss: 0.7916\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 26s 262ms/step - g_loss: 0.7953 - d_loss: 0.5934\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.8754 - d_loss: 0.6612\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 26s 262ms/step - g_loss: 0.8593 - d_loss: 0.6005\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.8725 - d_loss: 0.6156\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.7053 - d_loss: 0.7100\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.9409 - d_loss: 0.5906\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 26s 262ms/step - g_loss: 0.9314 - d_loss: 0.6373\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.5957 - d_loss: 0.7430\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 26s 257ms/step - g_loss: 0.9171 - d_loss: 0.6129\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 0.6745 - d_loss: 0.7372\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.9850 - d_loss: 0.5904\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 26s 263ms/step - g_loss: 0.9860 - d_loss: 0.6388\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 0.7469 - d_loss: 0.6806\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 29s 287ms/step - g_loss: 0.9834 - d_loss: 0.5162\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 27s 274ms/step - g_loss: 1.1580 - d_loss: 0.4667\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 27s 269ms/step - g_loss: 1.2330 - d_loss: 0.4764\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 26s 262ms/step - g_loss: 1.3866 - d_loss: 0.3974\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 1.8005 - d_loss: 0.4830\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 1.9377 - d_loss: 0.2557\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 1.1490 - d_loss: 0.5436\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 26s 258ms/step - g_loss: 1.3347 - d_loss: 0.4291\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 26s 259ms/step - g_loss: 1.1051 - d_loss: 0.9054\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 0.5735 - d_loss: 1.1699\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 26s 258ms/step - g_loss: 0.9097 - d_loss: 0.6162\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 26s 258ms/step - g_loss: 0.6715 - d_loss: 0.8945\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 26s 258ms/step - g_loss: 0.7371 - d_loss: 0.7543\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 26s 261ms/step - g_loss: 0.6375 - d_loss: 0.7763\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 26s 260ms/step - g_loss: 0.6905 - d_loss: 0.7231\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 27s 274ms/step - g_loss: 0.7374 - d_loss: 0.6811\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 28s 276ms/step - g_loss: 0.7546 - d_loss: 0.6703\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 27s 275ms/step - g_loss: 0.7570 - d_loss: 0.6762\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 28s 275ms/step - g_loss: 0.8029 - d_loss: 0.6418\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 28s 275ms/step - g_loss: 0.7175 - d_loss: 0.7094\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 28s 276ms/step - g_loss: 0.7152 - d_loss: 0.6634\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 28s 275ms/step - g_loss: 0.8156 - d_loss: 0.6726\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 28s 277ms/step - g_loss: 0.7128 - d_loss: 0.7161\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 28s 275ms/step - g_loss: 0.7205 - d_loss: 0.7283\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 28s 275ms/step - g_loss: 0.7587 - d_loss: 0.6436\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 27s 275ms/step - g_loss: 0.7477 - d_loss: 0.6919\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 28s 276ms/step - g_loss: 0.7522 - d_loss: 0.6800\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 28s 275ms/step - g_loss: 0.7232 - d_loss: 0.6765\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 28s 276ms/step - g_loss: 0.8137 - d_loss: 0.6175\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 28s 275ms/step - g_loss: 0.7454 - d_loss: 0.6727\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 28s 275ms/step - g_loss: 0.7342 - d_loss: 0.6551\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 27s 274ms/step - g_loss: 0.7217 - d_loss: 0.7066\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.7888 - d_loss: 0.6678\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 27s 274ms/step - g_loss: 0.7874 - d_loss: 0.6491\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 27s 270ms/step - g_loss: 0.7610 - d_loss: 0.6533\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 27s 270ms/step - g_loss: 0.7709 - d_loss: 0.6562\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 27s 269ms/step - g_loss: 0.7398 - d_loss: 0.7031\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 27s 270ms/step - g_loss: 0.7353 - d_loss: 0.6540\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.8064 - d_loss: 0.6346\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 27s 270ms/step - g_loss: 0.6746 - d_loss: 0.7181\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 27s 274ms/step - g_loss: 0.6985 - d_loss: 0.7010\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 27s 271ms/step - g_loss: 0.7609 - d_loss: 0.6547\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 27s 270ms/step - g_loss: 0.7178 - d_loss: 0.6998\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 27s 270ms/step - g_loss: 0.7670 - d_loss: 0.6624\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 29s 288ms/step - g_loss: 0.8113 - d_loss: 0.6684\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.6782 - d_loss: 0.7161\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.7615 - d_loss: 0.6599\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.6973 - d_loss: 0.6836\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 27s 273ms/step - g_loss: 0.6918 - d_loss: 0.7068\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.7779 - d_loss: 0.6864\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 27s 273ms/step - g_loss: 0.7330 - d_loss: 0.6673\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.7699 - d_loss: 0.6838\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 27s 271ms/step - g_loss: 0.6853 - d_loss: 0.6890\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.7223 - d_loss: 0.7168\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.7225 - d_loss: 0.6373\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 27s 272ms/step - g_loss: 0.8783 - d_loss: 0.7057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55bc4a5400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.fit(x_train, epochs=100, batch_size=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Decoding fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NBR = 10\n",
    "\n",
    "codes = np.random.normal(size=(NBR, code_size))\n",
    "decoded_imgs = generator.predict(codes)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(NBR):\n",
    "    ax = plt.subplot(1, NBR, i + 1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    #plt.title(str(codes[i]))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
