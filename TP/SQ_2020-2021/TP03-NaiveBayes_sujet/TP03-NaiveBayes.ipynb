{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP03 : Naive Bayes\n",
    "\n",
    "\n",
    "## I. Implémentation\n",
    "\n",
    "Pour estimer la vraisemblance, il y a plusieurs modèles (lois):\n",
    "- Loi multinomiale : pour les caracétristiques nominales\n",
    "- Loi de Bernoulli : lorsqu'on est interressé par l'apparence d'une caractéristique ou non (binaire)\n",
    "- loi normale : pour les caractéristiques numériques\n",
    "\n",
    "Dans ce TP, on va implémenter Naive Bayes pour les caractéristiques nominales (loi multinomiale). \n",
    "Dans notre modèle, on veut stocker des statistiques et pas des probabilités. \n",
    "L'intérêt est pour faciliter la mise à jours des statistiques (si par exemple, nous avons un autre dataset et on veut enrichir le modèle ; donc,  ce n'ai pas la peine d'entraîner de nouveau sur l'ancien dataset)\n",
    "\n",
    "Ici, on va utiliser le dataset \"jouer\" contenant des caractéristiques nominales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "jouer = pd.read_csv(\"datasets/jouer.csv\")\n",
    "\n",
    "X_jouer = jouer.iloc[:, :-1].values # Premières colonnes \n",
    "Y_jouer = jouer.iloc[:,-1].values # Dernière colonne \n",
    "\n",
    "# Afficher le dataset \"jouer\"\n",
    "jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1. Entraînement de la probabilité antérieure\n",
    "Etant donné le vecteur de sortie $Y$, on doit calculer la probabilité de chaque classe (différentes valeurs de $Y$)\n",
    "\n",
    "$$p(c_k) = \\frac{|\\{y / y \\in Y \\text{ et } y = c_k\\}|}{|Y|}$$\n",
    "\n",
    "Etant donné un vecteur $Y$ contenant des échantillons sous forme des catégories nominales (les classes dans ce cas), la fonction doit récupérer des statistiques afin de pouvoir calculer la probabilité antérieure de chaque classe. Donc, elle doit retourner  :\n",
    "- Un vecteur contenant les noms des classes\n",
    "- Un vecteur contenant les nombres d'occurrences de chaque classe dans le premier vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Compléter la fonction des stastistiques pour la probabilité antérieure\n",
    "def stat_anterieure(Y): \n",
    "    cls = np.unique(Y)\n",
    "    freq = []\n",
    "    # compléter à partir d'ici\n",
    "    return cls, np.array(freq)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : (array(['non', 'oui'], dtype=object), array([5, 9]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "stat_anterieure(Y_jouer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2. Entraînement de la probabilité de vraissemblance (loi multinomiale)\n",
    "\n",
    "Notre modèle doit garder le nombre des différentes valeurs d'une caractéristique $A$ et le nombre de ces valeurs dans chaque classe.\n",
    "Donc, étant donné un vecteur d'une caractéristique $A= X[:,j]$, un autre des $Y$ et un $C$ contenant la liste des classes, la fonction d'entrainement doit retourner : \n",
    "- $V$ : un vecteur contenant les différenntes catégories de $A$\n",
    "- une matrice conntenant le nombre d'occurrences de chaque catégorie de $V$ dans chaque classe  : \n",
    "   - les lignes représentent les catégories $v \\in V$ de la caréctéristique $A$\n",
    "   - les colonnes représentent les classes $c \\in C$ de $Y$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Compléter la fonction des statistiques de vraissemblance (1 seule caractéristique)\n",
    "def stat_vraissemblance_1(A, Y, C): \n",
    "    freq = []\n",
    "    V = np.unique(A)\n",
    "    # compléter à partir d'ici\n",
    "    return V, np.array(freq)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : (array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object), array([[3, 2],\n",
    "#         [0, 4],\n",
    "#         [2, 3]]))\n",
    "#---------------------------------------------------------------------\n",
    "C_t = np.array([\"non\", \"oui\"])\n",
    "stat_vraissemblance_1(X_jouer[:, 0], Y_jouer, C_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3. Entraînement loi multinomiale\n",
    "\n",
    "Notre modèle ($\\theta_{X, C}$) doit garder des statistiques sur les classes et aussi sur chaque catégorie de chaque caractéristique. Pour ce faire, on va représenter $\\theta$ comme un vecteur : \n",
    "- $\\theta[N+1]$ est un vecteur de $N$ éléments représentants des statistiques sur chaque caractéristique $j$, plus un élément (le dernier) pour les statistiques sur les classes.\n",
    "- Chaque élément est un dictionnaire (HashMap en Java)\n",
    "- Un élément des caractéristiques contient deux clés : \n",
    "    - **val** : pour récupérer la liste des noms des catégories de la caractéristique\n",
    "    - **freq**: pour récupérer une matrice représentant la fréquence de chaque caractéristique dans chaque classe\n",
    "- Un élément des classes contient deux clés : \n",
    "    - **cls** : pour récupérer la liste des noms des classes\n",
    "    - **freq**: pour récupérer la liste des fréquences de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction qui entraine Théta sur plusieurs caractéristiques\n",
    "# Rien à programmer ici\n",
    "# Notre théta est une liste des dictionnaires;\n",
    "# chaque dictionnaire contient la liste des catégories et la matrice des fréquences dela caractéristique respective à la colonne de X\n",
    "# On ajoute les statistiques antérieures des classes à la fin de résultat\n",
    "def entrainer_multi(X, Y): \n",
    "    Theta = []\n",
    "    \n",
    "    stats_c = {}\n",
    "    stats_c[\"cls\"], stats_c[\"freq\"] =  stat_anterieure(Y)\n",
    "    \n",
    "    for j in range(X.shape[1]): \n",
    "        stats = {}\n",
    "        stats[\"val\"], stats[\"freq\"] =  stat_vraissemblance_1(X[:, j], Y, stats_c[\"cls\"])\n",
    "        Theta.append(stats)\n",
    "    \n",
    "    Theta.append(stats_c)\n",
    "    return Theta\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "#   [{'freq': array([[3, 2],\n",
    "#          [0, 4],\n",
    "#          [2, 3]]),\n",
    "#   'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object)},\n",
    "#  {'freq': array([[2, 2],\n",
    "#          [2, 4],\n",
    "#          [1, 3]]), 'val': array(['chaude', 'douce', 'fraiche'], dtype=object)},\n",
    "#  {'freq': array([[4, 3],\n",
    "#          [1, 6]]), 'val': array(['haute', 'normale'], dtype=object)},\n",
    "#  {'freq': array([[2, 6],\n",
    "#          [3, 3]]), 'val': array(['non', 'oui'], dtype=object)},\n",
    "#  {'cls': array(['non', 'oui'], dtype=object), 'freq': array([5, 9])}]\n",
    "#---------------------------------------------------------------------\n",
    "Theta_jouer = entrainer_multi(X_jouer, Y_jouer)\n",
    "\n",
    "Theta_jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4. Estimation de la probabilité de vraissemblance (loi multinomiale)\n",
    "L'équation pour estimer la vraisemblance \n",
    "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}|}{|\\{y = c_k\\}|}$$\n",
    "\n",
    "Si, dans le dataset de test, on veut calculer la probabilité d'une valeur $v$ qui n'existe pas dans le dataset d'entrainnement ou qui n'existe pas pour une classe donnée, on aura une probabilité nulle. Ici, on doit appliquer une fonction de lissage qui donne une petite probabilité aux données non vues dans l'entrainnement. Le lissage qu'on va utiliser est celui de Lidstone. Lorsque $\\alpha = 1$ on l'appelle lissage de Laplace.\n",
    "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}| + \\alpha}{|\\{y = c_k\\}| + \\alpha * |V|}$$\n",
    "Où: \n",
    "- $\\alpha$ est une valeur donnée \n",
    "- $V$ est l'ensemble des différentes valeurs de $f_j$ (le vocabulaire)\n",
    "\n",
    "Etant donné : \n",
    "- $\\theta_j$ les paramètres de la caractéristique $j$ représentées comme dictionnaire\n",
    "    - **val** : pour récupérer la liste des noms des catégories de la caractéristique (vocabulaire $V$)\n",
    "    - **freq**: pour récupérer une matrice représentant la fréquence de chaque caractéristique dans chaque classe. C'est une matrice $|V|\\times|C|$\n",
    "- $v$ la valeur de la caractéristique $j$ dont on veut utiliser pour calculer les probabilités\n",
    "- $\\theta_c$ les paramètres des classes $C$ représentées comme dictionnaire\n",
    "    - **cls** : pour récupérer la liste des noms des classes\n",
    "    - **freq**: pour récupérer la liste des fréquences des classes\n",
    "    \n",
    "Cette fonction doit retourner : \n",
    "- Une liste $P[|C|]$ contenant les probabilités de la catégorie $v$ de $X_j$ sur toutes les classes $C$ \n",
    "- Elle doit prendre en cosidération le cas où la valeur $v$ n'existe pas dans le modèle entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compléter la fonction qui calcule la vraissamblance d'une valeur donnée\n",
    "def P_vraiss_multi(Theta_j, v, Theta_c, alpha=0.): \n",
    "    ind = np.where(Theta_j[\"val\"] == v)[0] #une liste des indices où se trouve la valeur v dans Theta_j[\"val\"]\n",
    "    # si la liste est vide, la valeur n'existe pas dans théta, sinon l'indice est dans ind[0]\n",
    "    # compléter à partir d'ici\n",
    "    return None\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : (array([0.4       , 0.33333333]), array([0.125     , 0.08333333]))\n",
    "#---------------------------------------------------------------------\n",
    "# Calcul :\n",
    "# La probabilité de jouer si temps = pluvieux \n",
    "# P(temps = pluvieux | jouer=oui) = (nbr(temps=pluvieux et jouer=oui)+alpha)/(nbr(jour=oui) + alpha * nbr_diff(temps)))\n",
    "# P(temps = pluvieux | jouer=oui) = (3 + 0)/(9 + 0) ==> 3 est le nombre de différentes valeurs de temps (entrainnement)\n",
    "# P(temps = pluvieux | jouer=oui) = 4/12 ==> 0.33333333333333333333333333333333333~\n",
    "\n",
    "# La probabilité de jouer si temps = neigeux \n",
    "# P(temps = neigeux | jouer=oui) = (nbr(temps=neigeux et jouer=oui)+alpha)/(nbr(jouer=oui) + alpha * nbr_diff(temps)))\n",
    "# P(temps = neigeux | jouer=oui) = (0 + 1)/(9 + 3) ==> 3 est le nombre de différentes valeurs de temps (entrainnement)\n",
    "# P(temps = neigeux | jouer=oui) = 1/13 ==> 0.0833333333333333333333333333333333333~\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "P_vraiss_multi(Theta_jouer[0], \"pluvieux\", Theta_jouer[-1]), P_vraiss_multi(Theta_jouer[0], \"neigeux\", Theta_jouer[-1], alpha=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5. Prédiction de la classe (loi multinomiale)\n",
    "Revenons maintenant à notre équation de prédiction \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n",
    "\n",
    "- On doit prédire un seule échantillon $x$. \n",
    "- La fonction doit retourner un vecteur des log-probabilité des classes\n",
    "- Si anter=false donc on n'utilise pas la probabilité antérieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Réaliser la fonction de prédiction des log des probabilités\n",
    "def predire(x, Theta, alpha=1., anter=True): \n",
    "    return None\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : (array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))\n",
    "#---------------------------------------------------------------------\n",
    "predire([\"pluvieux\", \"fraiche\", \"normale\", \"oui\"], Theta_jouer), predire([\"pluvieux\", \"fraiche\", \"normale\", \"oui\"], Theta_jouer, anter=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6. Regrouper en une classe (loi multinomiale)\n",
    "\n",
    "**Rien à programmer ici\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBMultinom(object): \n",
    "    \n",
    "    def __init__(self, alpha=1.): \n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def entrainer(self, X, Y):\n",
    "        self.Theta = entrainer_multi(X, Y)\n",
    "    \n",
    "    def predire(self, X, anter=True, prob=False): \n",
    "        Y_pred = []\n",
    "        cls = self.Theta[-1][\"cls\"]\n",
    "        for i in range(len(X)): \n",
    "            log_prob = predire(X[i,:], self.Theta, alpha=self.alpha, anter=anter)\n",
    "            if prob:\n",
    "                Y_pred.append(np.max(log_prob))\n",
    "            else:\n",
    "                Y_pred.append(cls[np.argmax(log_prob)])\n",
    "        return Y_pred\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : ['oui', 'non']\n",
    "#---------------------------------------------------------------------\n",
    "notre_modele = NBMultinom()\n",
    "notre_modele.entrainer(X_jouer, Y_jouer)\n",
    "X_test = np.array(\n",
    "    [[\"neigeux\", \"fraiche\", \"normale\", \"oui\"],\n",
    "     [\"neigeux\", \"fraiche\", \"haute\", \"oui\"]\n",
    "    ]\n",
    ")\n",
    "notre_modele.predire(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Application et analyse\n",
    "\n",
    "### II.1. Probabilité antérieure \n",
    "\n",
    "On veut tester l'effet de la probabilité antérieure.\n",
    "Pour ce faire, nous avons entraîné deux modèles\n",
    "- le premier prend en considération la probabilité antérieure\n",
    "- le premier ne prend pas en considération la probabilité antérieure (considère une distribution uniforme des classes)\n",
    "\n",
    "Pour tester si les modèles ont bien appris le dataset d'entraînement, on va les tester sur ce dataset et calculer le rapport de classification.\n",
    "\n",
    "**TODO : Analyser les résultats**\n",
    "- Que remarquez-vous ?\n",
    "- Est-ce que la probabilité antérieure dans ce cas est importante ?\n",
    "- Comment cette probabilité affecte le résultat ?\n",
    "- Quand on est sûr que l'utilisation ou non de cette probabilité donne de même résultats ?\n",
    "\n",
    "**Réponse**\n",
    "- ...\n",
    "- ...\n",
    "- ... \n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVEC Scikit-learn\n",
    "# ===================\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "nb_ant = CategoricalNB(alpha=1.0, fit_prior=True)\n",
    "nb_sans_ant = CategoricalNB(alpha=1.0, fit_prior=False)\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "X_jouer_enc = enc.fit_transform(X_jouer)\n",
    "nb_ant.fit(X_jouer_enc, Y_jouer)\n",
    "nb_sans_ant.fit(X_jouer_enc, Y_jouer)\n",
    "\n",
    "Y_notre_ant = nb_ant.predict(X_jouer_enc)\n",
    "Y_notre_sans_ant = nb_sans_ant.predict(X_jouer_enc)\n",
    "\n",
    "# AVEC notre modèle (juste pour voir comment l'utiliser)\n",
    "# =======================================================\n",
    "#notre_modele = NBMultinom()\n",
    "#notre_modele.entrainer(X_jouer, Y_jouer)\n",
    "#Y_notre_ant = notre_modele.predire(X_jouer)\n",
    "#Y_notre_sans_ant = notre_modele.predire(X_jouer, anter=False) \n",
    "\n",
    "# Le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Notre modèle avec probabilité antérieure (a priori)\")\n",
    "print(classification_report(Y_notre_ant, Y_jouer))\n",
    "\n",
    "\n",
    "print(\"Notre modèle sans probabilité antérieure (a priori)\")\n",
    "print(classification_report(Y_notre_sans_ant, Y_jouer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Lissage\n",
    "\n",
    "On veut tester l'effet de lissage de Lidstone, on entraine 3 modèles : \n",
    "- alpha = 1 (lissage de Laplace)\n",
    "- alpha = 0.5\n",
    "- alpha = 0 (sans lissage)\n",
    "\n",
    "\n",
    "\n",
    "**TODO : Analyser les résultats**\n",
    "- Que remarquez-vous ?\n",
    "- Est-ce que le lissage affecte la performance dans ce cas ? Pourquoi ?\n",
    "- Pourquoi Scikit-learn n'accepte pas la valeur alpha=0 et affiche une alerte \"UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\" ?\n",
    "- Quelle est l'intéret du lissage ?\n",
    "\n",
    "**Réponse**\n",
    "- ...\n",
    "- ...\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBC_10 = CategoricalNB(alpha=1.0)\n",
    "NBC_10.fit(X_jouer_enc, Y_jouer)\n",
    "\n",
    "NBC_05 = CategoricalNB(alpha=0.5)\n",
    "NBC_05.fit(X_jouer_enc, Y_jouer)\n",
    "\n",
    "NBC_00 = CategoricalNB(alpha=0.)\n",
    "NBC_00.fit(X_jouer_enc, Y_jouer)\n",
    "\n",
    "Y_10 = NBC_10.predict(X_jouer_enc)\n",
    "Y_05 = NBC_05.predict(X_jouer_enc)\n",
    "Y_00 = NBC_00.predict(X_jouer_enc)\n",
    "\n",
    "\n",
    "print(\"Alpha = 1.0\")\n",
    "print(classification_report(Y_10, Y_jouer))\n",
    "\n",
    "print(\"Alpha = 0.5\")\n",
    "print(classification_report(Y_05, Y_jouer))\n",
    "\n",
    "print(\"Alpha = 0.0\")\n",
    "print(classification_report(Y_00, Y_jouer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3. Comparaison avec d'autres algorithmes\n",
    "\n",
    "Ici, on va essayer d'appliquer l'apprentissage automatique sur la détection de spam. \n",
    "Chaque message dans le dataset est représenté en utilisant un modèle \"Sac à mots\" (BoW : Bag of Words).\n",
    "Dans l'entrainement, on récupère les différents mots qui s'apparaissent dans les messages. \n",
    "Chaque mot va être considéré comme une caractéristique. \n",
    "Donc, pour chaque message, la valeur de la caractéristique est la fréquence de son mot dans le message. \n",
    "Par exemple, si le mot \"good\" apparait 3 fois dans le message, donc la caractéristique \"good\" aura la valeur 3 dans ce message.\n",
    "\n",
    "Notre implémentation n'est pas adéquate pour la nature de ce problème. \n",
    "Dans Scikit-learn, le [sklearn.naive_bayes.CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) est similaire à notre implémentation. \n",
    "L'algorithme adéquat pour ce type de problème est [sklearn.naive_bayes.MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
    "\n",
    "Le dataset utilisé est [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset).\n",
    "Les algorithmes comparés :\n",
    "- Naive Bayes\n",
    "- Arbre de décision\n",
    "- Regression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv(\"datasets/spam.csv\", encoding=\"latin-1\")\n",
    "messages = messages.rename(columns={\"v1\": \"classe\", \"v2\": \"texte\"})\n",
    "messages = messages.filter([\"texte\", \"classe\"])\n",
    "\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import timeit\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "temps_train = {}\n",
    "temps_test = {}\n",
    "\n",
    "rappel = {}\n",
    "precision = {}\n",
    "\n",
    "msg_train, msg_test, Y_train, Y_test = train_test_split(messages[\"texte\"],messages[\"classe\"],test_size=0.2, random_state=0)\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train = count_vectorizer.fit_transform(msg_train)\n",
    "X_test = count_vectorizer.transform(msg_test)\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# ENTRAINEMENT \n",
    "# ==================================\n",
    "    \n",
    "#entrainement Naive Bayes\n",
    "naive_bayes = MultinomialNB()\n",
    "temps_debut = timeit.default_timer()\n",
    "naive_bayes.fit(X_train, Y_train)\n",
    "temps_train[\"naive_bayes\"] = timeit.default_timer() - temps_debut\n",
    "    \n",
    "#entrainement CART\n",
    "arbre_decision = DecisionTreeClassifier()\n",
    "temps_debut = timeit.default_timer()\n",
    "arbre_decision.fit(X_train, Y_train)\n",
    "temps_train[\"arbre_decision\"] = timeit.default_timer() - temps_debut\n",
    "    \n",
    "#entrainement Régression logitique\n",
    "reg_log = LogisticRegression(solver=\"lbfgs\") #solver=sag est plus lent; donc j'ai choisi le plus rapide\n",
    "temps_debut = timeit.default_timer()\n",
    "reg_log.fit(X_train, Y_train)\n",
    "temps_train[\"reg_log\"] = timeit.default_timer() - temps_debut\n",
    "    \n",
    "# ==================================\n",
    "# TEST \n",
    "# ==================================\n",
    "    \n",
    "#test Naive Bayes\n",
    "temps_debut = timeit.default_timer()\n",
    "Y_naive_bayes = naive_bayes.predict(X_test)\n",
    "temps_test[\"naive_bayes\"] = timeit.default_timer() - temps_debut\n",
    "    \n",
    "    \n",
    "#test CART\n",
    "temps_debut = timeit.default_timer()\n",
    "Y_arbre_decision = arbre_decision.predict(X_test)\n",
    "temps_test[\"arbre_decision\"] = timeit.default_timer() - temps_debut\n",
    "    \n",
    "#test Régression logitique\n",
    "temps_debut = timeit.default_timer()\n",
    "Y_reg_log = reg_log.predict(X_test)\n",
    "temps_test[\"reg_log\"] = timeit.default_timer() - temps_debut\n",
    "    \n",
    "# ==================================\n",
    "# PERFORMANCE \n",
    "# ==================================\n",
    "# Ici, on va considérer une classification binaire avec une seule classe \"spam\" \n",
    "# On ne juge pas le classifieur sur sa capacité de détecter les non spams\n",
    "    \n",
    "precision[\"naive_bayes\"] = precision_score(Y_test, Y_naive_bayes, pos_label=\"spam\")\n",
    "precision[\"arbre_decision\"] = precision_score(Y_test, Y_arbre_decision, pos_label=\"spam\")\n",
    "precision[\"reg_log\"] = precision_score(Y_test, Y_reg_log, pos_label=\"spam\")\n",
    "    \n",
    "rappel[\"naive_bayes\"] = recall_score(Y_test, Y_naive_bayes, pos_label=\"spam\")\n",
    "rappel[\"arbre_decision\"] = recall_score(Y_test, Y_arbre_decision, pos_label=\"spam\")\n",
    "rappel[\"reg_log\"] = recall_score(Y_test, Y_reg_log, pos_label=\"spam\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.1. Temps d'entraînement et de test\n",
    "\n",
    "Combien de temps chaque algorithme prend pour entrainer le même dataset d'entrainement et combien de temps pour tester le même dataset de test.\n",
    "\n",
    "**TODO : Analyser les résultats**\n",
    "- Que remarquez-vous concernant le temps d'entrainement ? Pourquoi nous avons eu ces résultats en se basant sur les algorithmes ?\n",
    "- Que remarquez-vous concernant le temps de test ? Pourquoi nous avons eu ces résultats en se basant sur les algorithmes ?\n",
    "\n",
    "**Réponse**\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"Alogorithme\" : [\"Naive Bayes\", \"Arbre de decision\", \"Regression logistique\"],\n",
    "    \"Temps d'entrainement\" : [temps_train[\"naive_bayes\"], temps_train[\"arbre_decision\"], temps_train[\"reg_log\"]],\n",
    "    \"Temps de test\" : [temps_test[\"naive_bayes\"], temps_test[\"arbre_decision\"], temps_test[\"reg_log\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.2. Qualité de prédiction\n",
    "\n",
    "Comment chaque algorithme performe sur le dataset de test dans le cas de détection de spams (spam: est la classe positive).\n",
    "\n",
    "**TODO : Analyser les résultats**\n",
    "\n",
    "On remarque que Naive Bayes surpasse les deux autres algorithmes dans la détection de spams. (répond avec oui ou non, sans argumentation)\n",
    "- Est-ce que ceci preuve que Naive Bayes est meilleur que les autres algorithmes sur n'importe quel problème ?\n",
    "- Est-ce que ceci preuve que Naive Bayes peut donner de meilleurs résultats que les autres algorithmes sur des problèmes similaires ?\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "Est-ce que ceci preuve que Naive Bayes est meilleur que les autres algorithmes sur n'importe quel problème ?\n",
    "- [ ] Oui\n",
    "- [ ] Non\n",
    "\n",
    "Est-ce que ceci preuve que Naive Bayes peut donner de meilleurs résultats que les autres algorithmes sur des problèmes similaires ?\n",
    "- [ ] Oui\n",
    "- [ ] Non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"Alogorithme\" : [\"Naive Bayes\", \"Arbre de decision\", \"Regression logistique\"],\n",
    "    \"Rappel\" : [rappel[\"naive_bayes\"], rappel[\"arbre_decision\"], rappel[\"reg_log\"]],\n",
    "    \"Precision\" : [precision[\"naive_bayes\"], precision[\"arbre_decision\"], precision[\"reg_log\"]]\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
