{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12eabd08",
   "metadata": {},
   "source": [
    "# Workshop02 : Réseaux de neurones (Auto-encodeurs et CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4052f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image  as mpimg\n",
    "from   matplotlib        import colors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D, Dropout, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca91572",
   "metadata": {},
   "source": [
    "## Pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorsqu'on lit l'image PNG avec 3 canaux, \n",
    "# les parties transparentes sont transformées en noir \n",
    "# Or, normalement elle doivent être en blanc\n",
    "# Donc, j'ai supposé que la partie transparente est encodée sous forme (0, 0, 0, 0)\n",
    "# Dans ce cas, on la transforme à (255, 255, 255)\n",
    "def rgb_vers_rgba(img):\n",
    "    h, w, c = img.shape\n",
    "    if c != 4:\n",
    "        return img\n",
    "    \n",
    "    resh_img = img.reshape([-1, c])\n",
    "    new_img = []\n",
    "    \n",
    "    for i in range(len(resh_img)):\n",
    "        l = resh_img[i, :]\n",
    "        if l[3] == 0:\n",
    "            new_img.append([255, 255, 255])\n",
    "        else:\n",
    "            new_img.append(l[:-1])\n",
    "    return np.array(new_img).reshape([h, w, 3])\n",
    "    \n",
    "rgb_vers_rgba(np.array([\n",
    "    [[255, 200, 100, 255], [255, 200, 100, 255], [255, 200, 100, 0]],\n",
    "    [[255, 200, 100, 255], [0, 0, 0, 0], [255, 200, 100, 200]]\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOC = 'pokemon/'\n",
    "\n",
    "types_df = pd.read_csv(DATASET_LOC + 'pokemon.csv')\n",
    "types_df = types_df.drop(['Type2'], axis=1)\n",
    "\n",
    "def generer_dataset(ext='*.png'):\n",
    "    d = DATASET_LOC + 'images/images'\n",
    "    path = Path(d)\n",
    "    fichiers = list(path.glob(ext))\n",
    "    noms = [os.path.split(fichier)[1] for fichier in fichiers ]\n",
    "    image_df = pd.concat([pd.Series(noms, name='Name'), pd.Series(fichiers, name='path').astype(str)], axis=1)\n",
    "    image_df['Name'] = image_df['Name'].apply(lambda x: re.sub(r'\\.\\w+$', '', x))\n",
    "    \n",
    "    df = image_df.merge(types_df, on='Name')\n",
    "    \n",
    "    imgs = []\n",
    "    for index in range(df.shape[0]):\n",
    "        img = tf.io.decode_image(tf.io.read_file(df['path'][index]), channels=0)\n",
    "        img = rgb_vers_rgba(img.numpy())\n",
    "        imgs.append(img)\n",
    "#         imgs.append(mpimg.imread(df['path'][index]))\n",
    "    \n",
    "    return np.array(imgs), df['Type1'].values\n",
    "\n",
    "def afficher_images(imgs, y, n):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(imgs[i]) # recontruct the matrix\n",
    "        plt.gray()\n",
    "        plt.title(\"T: \" + str(y[i]))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "def classer_images(imgs, cls, cls_mdl, n):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    Y_pred = cls_mdl.predict(imgs[0:n])\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(imgs[i]) # recontruct the matrix\n",
    "        plt.gray()\n",
    "        plt.title(\"T: \" + str(cls[i]) + ', P: ' + str(Y_pred[i]))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "print('Fonction definie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset d'entraînement\n",
    "X_train, Y_train = generer_dataset()\n",
    "\n",
    "X_train = X_train / 255\n",
    "\n",
    "# 721 images de 120X120 pixels chaque pixel est encodé sur 3 canaux \n",
    "print(X_train.shape)\n",
    "\n",
    "afficher_images(X_train, Y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ee2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset de test\n",
    "X_test, Y_test = generer_dataset('*.jpg')\n",
    "\n",
    "X_test = X_test / 255\n",
    "\n",
    "# 721 images de 120X120 pixels chaque pixel est encodé sur 4 canaux \n",
    "print(X_test.shape)\n",
    "\n",
    "afficher_images(X_test, Y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67dd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pokemon_type_enc = LabelEncoder()\n",
    "\n",
    "Y_train = pokemon_type_enc.fit_transform(Y_train)\n",
    "Y_test = pokemon_type_enc.transform(Y_test)\n",
    "\n",
    "cls_len = len(np.unique(Y_train))\n",
    "\n",
    "Y_train_onehot = tf.keras.utils.to_categorical(Y_train, cls_len)\n",
    "Y_test_onehot = tf.keras.utils.to_categorical(Y_test, cls_len)\n",
    "\n",
    "# Le dataset de test n'est pas vraiment représentatif : les classes 7 et 11 \n",
    "# ne figurent pas dans le test\n",
    "np.unique(Y_train), np.unique(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16303ef",
   "metadata": {},
   "source": [
    "## 1. Classement CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bff90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68a2e58",
   "metadata": {},
   "source": [
    "## 2. Auto-encodeur de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c6e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ffd538",
   "metadata": {},
   "source": [
    "## 3. Auto-encodeur de clustering pour classement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a63ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f857677",
   "metadata": {},
   "source": [
    "## 4. Génération des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389be86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
