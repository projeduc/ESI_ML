% !TEX TS-program = pdflatex
% !TeX program = pdflatex
% !TEX encoding = UTF-8
% !TEX spellcheck = fr

\documentclass[xcolor=table]{beamer}

\input{options}

\title[ML : Préparation des données et évaluation] %
{Machine Learning \\Préparation des données et évaluation} 

\changegraphpath{../img/preparation/}

\begin{document}
	
\begin{frame}
	\frametitle{Machine Learning}
	\framesubtitle{Préparation des données et évaluation : Introduction}
	
	\begin{figure}
		\centering
		\hgraphpage[.4\textwidth]{crisp-dm.png}
		\caption{CRISP-DM (Cross-industry standard process for data mining)}
	\end{figure}
	
\end{frame}


\begin{frame}
	\frametitle{Machine Learning}
	\framesubtitle{Préparation des données et évaluation : Plan}
	
	\begin{multicols}{2}
		%	\small
		\tableofcontents
	\end{multicols}
\end{frame}

\section{Collection des données}

\subsection{Qualité des données}

\begin{frame}
\frametitle{Collection des données}
\framesubtitle{Qualité des données}

\begin{itemize}
	\item Taille : Nombre des échantillons (enregistrements)
	\item Le nombre et le type de caractéristiques (nominales, binaires, ordinales ou continues).
	\item Le nombre des erreurs d'annotation
	\item La quantité de bruits dans les données: erreurs et exceptions
\end{itemize}

\end{frame}


\subsection{Intégration des données}

\begin{frame}
\frametitle{Collection des données}
\framesubtitle{Intégration des données}

\begin{itemize}
	\item \optword{Sources des données}
	\begin{itemize}
		\item Données structurées : \expword{BD, tabulateurs (CSV, etc.)}
		\item Données semi-structurées : \expword{XML, JSON, etc.}
		\item Données non structurées : \expword{documents textes, images, métadonnées, etc.}
	\end{itemize}
	\item \optword{Intégrité des données}
	\begin{itemize}
		\item Conformité des fichiers XML à leurs définitions DTD
		\item Séparateurs correctes des fichiers CSV
	\end{itemize}
	\item \optword{Fusionnement des données (joindre les schémas)}
	\begin{itemize}
		\item Problème de nommage : \expword{bd1.numclient, bd2.clientid}
		\item Conflits de valeurs : \expword{bd1.taille(cm), bd2.taille(pouces)}
		\item Redondance : attributs calculés et enregistrements identiques.
		\item Types différents des attributs : \expword{bd1.temperature (froid, chaud, ...), bd2.temperature (15, 23, ...)}
	\end{itemize}
\end{itemize}

\end{frame}


\subsection{Annotation (Étiquetage) des données}

\begin{frame}
\frametitle{Collection des données}
\framesubtitle{Annotation (Étiquetage) des données : Annotation interne}

\begin{itemize}
	\item Une équipe chargée par l'annotation
	\item Meilleure s'il y a suffisamment de ressources humaines, financières et du temps
	\item \textbf{Avantages} 
	\begin{itemize}
		\item Capacité à suivre le progrès
		\item Bonne qualité
	\end{itemize}
	\item \textbf{Inconvénients}
	\begin{itemize}
		\item Trop lente: si on gagne de la qualité, on va perdre du temps.
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Collection des données}
\framesubtitle{Annotation (Étiquetage) des données : Externalisation (Outsourcing)}

\begin{itemize}
	\item Embaucher des travailleurs indépendants (freelancers)
	\item S'il n'y a pas suffisamment de ressources humaines ou du temps
	\item \textbf{Étapes}
	\begin{enumerate}
		\item Préparer les données et fixer le temps exigé pour les annoter
		\item Diviser les sur des sous ensembles
		\item Publier des offres d'emploi sur les médias sociaux
	\end{enumerate}
	\item \textbf{Avantages} 
	\begin{itemize}
		\item On connait ceux qu'on a embauché : On peut vérifier leurs compétences
	\end{itemize}
	\item \textbf{Inconvénients}
	\begin{itemize}
		\item Préparation des instructions détaillées de l'annotation
		\item Temps de soumission et vérification des tâches
		\item Création d'un flux de travail : une interface qui aide les annotateurs.
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Collection des données}
\framesubtitle{Annotation (Étiquetage) des données : Crowdsourcing}

\begin{columns}
\begin{column}{0.78\textwidth}
\begin{itemize}
	\item Utiliser des plateformes de crowdsourcing.
	\item Ex. \expword{Amazon Mechanical Turk (MTurk) et Clickworker}.
	\item \textbf{Types de crowdsourcing}
	\begin{enumerate}
		\item \optword{Explicite} : En demandant directement des contributions
		\item \optword{Implicite} : En intégrant des tâches dans d’autres formes
		\begin{itemize}
			\item Tâches inévitables (Ex. \expword{reCAPTCHA})
			\item Jeux ayant des objectifs (Ex. \expword{jeu ESP})
		\end{itemize}
	\end{enumerate}
\end{itemize}
\end{column}
\begin{column}{0.22\textwidth}
	\hgraphpage{captcha.png}
\end{column}
\end{columns}

\begin{itemize}
	\item \textbf{Avantages} 
	\begin{itemize}
		\item Des résultats rapides
		\item Coûts abordables
	\end{itemize}
	\item \textbf{Inconvénients}
	\begin{itemize}
		\item Qualité des annotations
		\item Préparation des instructions détaillées sur le processus d'annotation
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}
	\frametitle{Collection des données}
	\framesubtitle{Annotation (Étiquetage) des données : Évaluation (Kappa ; classification)}
	
	\begin{itemize}
		\item Concordance inter-juges (fiabilité inter-évaluateurs) 
	\end{itemize}

\begin{columns}
\begin{column}{0.6\textwidth}
	\begin{itemize}
%		\item Concordance inter-juges (fiabilité inter-évaluateurs) 
		\item \optword{Kappa de Cohen}
		\begin{itemize}
			\item Mesure l'agrément entre deux juges et deux catégories
			\item $K = \frac{P_o - P_e}{1 - P_e}$
			\item $P_o = \frac{a + d}{a+b+c+d}$
			\item $P_{oui} = \frac{a+b}{a+b+c+d} * \frac{a+c}{a+b+c+d}$
			\item $P_{non} = \frac{c+d}{a+b+c+d} * \frac{b+d}{a+b+c+d}$
			\item $P_e = P_{oui} + P_{non}$
			\item \expword{sklearn.metrics.cohen\_kappa\_score}
		\end{itemize}
	\end{itemize}
\end{column}
\begin{column}{0.4\textwidth}
	\begin{tabular}{|c|c|c|c|}
		\cline{3-4}
		\multicolumn{2}{c|}{}& \multicolumn{2}{c|}{B} \\
		\cline{3-4}
		\multicolumn{2}{c|}{}& Oui & Non \\
		\hline
		\multirow{2}{*}{A} & Oui & a & b \\
		\cline{2-4}
		& Non & c & d \\
		\hline
	\end{tabular}
\end{column}
\end{columns}

\begin{itemize}
	\item \optword{Pi de Scott}
	\begin{itemize}
		\item Comme Cohen mais $P_e$ est calculée différemment (multi-classes)
	\end{itemize}
	\item \optword{Kappa de Fleiss}
	\begin{itemize}
		\item Généralisation de Pi de Scott pour plus de deux évaluateurs
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}
	\frametitle{Collection des données}
	\framesubtitle{Annotation (Étiquetage) des données : Évaluation (Corrélation ; régression)}
	
	\begin{itemize}
		\item \optword{Pearson}
		\begin{itemize}
			\item Espace continu des valeurs (régression)
			\item $r_{Y^{(1)},Y^{(2)}} = \frac{covariance(Y^{(1)},Y^{(2)})}{\sigma_{Y^{(1)}} \sigma_{Y^{(2)}}}$
			\item \expword{scipy.stats.pearsonr}
		\end{itemize}
		\item \optword{Spearman}
		\begin{itemize}
			\item Espace ordinal des valeurs
			\item $\rho_{Y^{(1)},Y^{(2)}} = \frac{covariance(rg(Y^{(1)}),rg(Y^{(2)}))}{\sigma_{rg(Y^{(1)})} \sigma_{rg(Y^{(2)})}}$
			\item $rg$ est la fonction rand ; l'ordre croissant
			\item \expword{scipy.stats.spearmanr}
		\end{itemize}
		\item \optword{Kendall}
		\begin{itemize}
			\item Espace ordinal des valeurs
			\item $\tau_{Y^{(1)},Y^{(2)}} = \frac{2}{2 (n-1)} \sum_{i<j} signe(y^{(1)}_i - y^{(1)}_j) signe(y^{(2)}_i - y^{(2)}_j)$
			\item \expword{scipy.stats.kendalltau}
		\end{itemize}
	\end{itemize}
	
\end{frame}

\subsection{Nettoyage des données}

\begin{frame}
	\frametitle{Collection des données}
	\framesubtitle{Nettoyage des données : Problèmes}
	
	\begin{itemize}
		\item \optword{Valeurs omises (données non disponibles)}
		\begin{itemize}
			\item Mauvais fonctionnement de l'équipement
			\item Incohérences avec d'autres données et donc supprimées
			\item Non saisies car non (ou mal) comprises
			\item Considérées peu importantes au moment de la saisie
		\end{itemize}
		\item \optword{Échantillons dupliqués}
		\begin{itemize}
			\item Plusieurs sources de données
		\end{itemize}
		\item \optword{Des mauvaises annotations}
		\begin{itemize}
			\item Incohérence dans les conventions de nommage
		\end{itemize}
		\item \optword{Bruit (erreur ou variance aléatoire d'une variable mesurée)}
		\begin{itemize}
			\item Instrument de mesure défectueux
			\item Problème de saisie
			\item Problème de transmission
		\end{itemize}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Collection des données}
	\framesubtitle{Nettoyage des données : Solutions possibles}
	
	\begin{itemize}
		\item \optword{Valeurs omises (données non disponibles)}
		\begin{itemize}
			\item Suppression ou saisie manuelle
			\item Remplacement par une constante globale. Ex., "inconnu" ou "0".
			\item Remplacement par la moyenne (numériques), préférence : même classe.
			\item Remplacement par la valeur la plus fréquente (nominales).
		\end{itemize}
		\item \optword{Échantillons dupliqués}
		\begin{itemize}
			\item Suppression
		\end{itemize}
		\item \optword{Des mauvaises annotations}
		\begin{itemize}
			\item Mesurer la fiabilité inter-évaluateurs
		\end{itemize}
		\item \optword{Bruit} 
		\begin{itemize}
			\item Clustering pour détecter les exceptions
			\item Détection automatique des valeurs suspectes et vérification humaine.
			\item Lissage des données par des méthodes de régression.
		\end{itemize}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Collection des données}
	\framesubtitle{Un peu d'humour}
	
	\begin{center}
		\vgraphpage{humour-collection.jpg}
	\end{center}
	
\end{frame}

\section{Transformation des données}

%\begin{frame}
%	\frametitle{Transformation des données}
%	
%\end{frame}

\subsection{Valeurs numériques}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Valeurs numériques : Discrétisation par groupement (binning, bucketing)}
	
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\hgraphpage{bucketing-1.png}
			
			\vspace{-6pt}
			\begin{center}
				quantiles
			\end{center}
		\end{column}
		\begin{column}{0.5\textwidth}
			\hgraphpage{bucketing-2.png}
			
			\vspace{-6pt}
			\begin{center}
				plages identiques
			\end{center}
		\end{column}
	\end{columns}

	\begin{center}
		Exemple de discrétisation par regroupement \cite{2021-google-prep}
	\end{center}

\begin{itemize}
	\item lorsqu'il n'y a pas de relation linéaire avec la sortie
	\item \expword{sklearn.preprocessing.KBinsDiscretizer}
\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Valeurs numériques : Normalisation}
	
	\hgraphpage{norm.png}
	
	\begin{center}
		Comparaison entre les fonction de normalisation \cite{2021-google-prep}
	\end{center}
	
\end{frame}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Valeurs numériques : Normalisation (Coupure)}
	
	\begin{columns}
	\begin{column}{.5\textwidth}
	\[x' = \begin{cases}
	\alpha & \text{si } x \ge \alpha \\
	\beta & \text{si } x \le \beta \\
	x & \text{sinon}
	\end{cases}
	\]
	
	\begin{itemize}
		\item On utilise cette normalisation si
		\begin{itemize}
			\item il y a des valeurs aberrantes extrêmes.
		\end{itemize}
		\item \textbf{Exemple}
		\begin{itemize}
			\item Nombre des chambres par personne
		\end{itemize}
		\item \expword{numpy.clip}
	\end{itemize}
	\end{column}
	\begin{column}{.5\textwidth}
		\hgraphpage{norm-coupure.png}
		
		\begin{center}
			Exemple de coupure \cite{2021-google-prep}
		\end{center}
	\end{column}
 \end{columns}
	
\end{frame}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Valeurs numériques : Normalisation (Mise à l'échelle min-max)}
	
%	\begin{columns}
%	\begin{column}{.6\textwidth}
	\[x' = \frac{x - x_{min}}{x_{max} - x_{min}}\]
	
	\begin{itemize}
		\item On utilise cette normalisation si
		\begin{itemize}
			\item On sait les limites inférieures et supérieures
			\item Les valeurs sont presque uniformément réparties sur cette plage
		\end{itemize}
		\item \textbf{Exemple}
		\begin{itemize}
			\item \textbf{Bon} : les ages
			\item \textbf{Mauvais} : les revenus (peu de personnes avec grand revenu)
		\end{itemize}
		\item \expword{sklearn.preprocessing.MinMaxScaler}
	\end{itemize}
%	\end{column}
%	\begin{column}{.4\textwidth}
%%		\hgraphpage{norm-minmax.png}
%	\end{column}
%\end{columns}
	
\end{frame}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Valeurs numériques : Normalisation (Mise à l'échelle log)}
	
	\begin{columns}
		\begin{column}{.5\textwidth}
			
	\[x' = \log(x)	\]
	
	\begin{itemize}
		\item On utilise cette normalisation lorsque
		\begin{itemize}
			\item la caractéristique conforme à la loi de puissance
		\end{itemize}
		\item \textbf{Exemple}
		\begin{itemize}
			\item Nombre des chambres par personne
		\end{itemize}
		\item \expword{numpy.log}
	\end{itemize}
	\end{column}
	\begin{column}{.5\textwidth}
		\hgraphpage{norm-log.png}
		
		\begin{center}
			Exemple de normalisation log \cite{2021-google-prep}
		\end{center}
	\end{column}
\end{columns}

\end{frame}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Valeurs numériques : Normalisation (Z-score, standardisation)}
	
	\begin{columns}
	\begin{column}{.5\textwidth}
	\[x' = \frac{x - \mu}{\sigma}	\]
	
	\begin{itemize}
		\item On utilise cette normalisation si
		\begin{itemize}
			\item il n'y a pas trop de valeurs aberrantes.
			\item on veut avoir une moyenne de 0 et déviation standard de 1
		\end{itemize}
		\item Exemple
		\begin{itemize}
			\item Nombre des chambres par personne
		\end{itemize}
		\item \expword{sklearn.preprocessing.StandardScaler}
	\end{itemize}
	\end{column}
	\begin{column}{.5\textwidth}
		\hgraphpage{norm-z.png}
		
		\begin{center}
			Exemple de standardisation \cite{2021-google-prep}
		\end{center}
	\end{column}
\end{columns}
	
\end{frame}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Valeurs numériques : Génération de caractéristiques}
	
%	\begin{columns}
%		\begin{column}{.5\textwidth}
			
			\begin{itemize}
				\item On utilise la génération de caractéristiques lorsque
				\begin{itemize}
					\item on veut avoir des représentations complexes 
				\end{itemize}
				\item \optword{Génération polynomiale} (les interactions)
				\begin{itemize}
					\item $(X_1, X_2, \ldots) \longrightarrow (1, X_1, X_2, X_1 X_2, X_1^2, X_2^2, \ldots)$
					\item \expword{sklearn.preprocessing.PolynomialFeatures}
				\end{itemize}
				\item \optword{Auto-encodeurs épars}
				\begin{itemize}
					\item Un réseaux de neurones avec apprentissage non supervisé 
					\item Il vise à représenter les échantillon avec plus de caractéristiques (une représentation vectorielle avec plus de dimensionnalité)
				\end{itemize}
			\end{itemize}
%		\end{column}
%		\begin{column}{.5\textwidth}
%			\hgraphpage{norm-z.png}
%		\end{column}
%	\end{columns}
	
\end{frame}

\subsection{Valeurs nominales}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Valeurs nominales : Encodage}
	
	\begin{itemize}
		\item \optword{Encodage ordinal}
		\begin{itemize}
			\item l'API utilisé pour l'entraînement n'accepte pas des chaines de caractères
			\item l'algorithme d'apprentissage ne considère pas les catégories comme ordonnées : Naïve Bayes multinomial 
			\item ou si l'ordre des catégories est important
			\item \expword{sklearn.preprocessing.OrdinalEncoder}
		\end{itemize}
		\item \optword{Encodage One-Hot}
		\begin{itemize}
			\item Lorsqu'on veut donner la même chance aux différentes catégories
			\item Chaque catégorie de la caractéristique sera encodée sous forme binaire dans une colonne à part
			\item \expword{sklearn.preprocessing.OneHotEncoder}
		\end{itemize}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Transformation des données}
	\framesubtitle{Un peu d'humour}
	
%	\begin{center}
		\hgraphpage{humour-transformation.jpeg}
%	\end{center}
	
\end{frame}

\section{Échantillonnage et fractionnement des données}

%\begin{frame}
%	\frametitle{Échantillonnage et fractionnement des données}
%	
%\end{frame}

\subsection{Données déséquilibrées}

\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Données déséquilibrées}
	
	\begin{table}
	\SetTblrInner{rowsep=0pt,colsep=1pt}
	\begin{tblr}{
			colspec = {p{0.3\textwidth}p{0.5\textwidth}},
			row{odd} = {lightblue, font=\small},
			row{even} = {lightyellow, font=\small},
			row{1} = {darkblue, font=\bfseries},
		}
			\textcolor{white}{Degré de déséquilibre} & \textcolor{white}{Proportion de classe minoritaire} \\
			léger & 20-40\% de données \\
			modéré & 1-20\% de données \\
			extrême &	\textless 1\% de données \\
	\end{tblr}
	\caption{Degré de déséquilibre \cite{2021-google-prep}}
	\end{table}

	\begin{itemize}
		\item \url{https://github.com/scikit-learn-contrib/imbalanced-learn}
		\item \textbf{pip install -U imbalanced-learn}
		\item \textbf{conda install -c conda-forge imbalanced-learn}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Données déséquilibrées : Sous échantillonnage}
	
	\begin{itemize}
		\item Supprimer des échantillons de la classe majoritaire (downsampling)
		\item Calibrer le modèle (upweithing)
		\item \optword{Suppression aléatoire}
		\begin{itemize}
			\item \expword{imblearn.under\_sampling.RandomUnderSampler}
		\end{itemize}
		\item \optword{Centroids des clusters}
		\begin{itemize}
			\item Utiliser \keyword{K-Means}  sur la classe majoritaire (avec K les nombre des échantillons voulus)
			\item Prendre le centre de chaque cluster comme représentant
			\item \expword{imblearn.under\_sampling.ClusterCentroids}
		\end{itemize}
		\item \optword{Liens de Tomek}
		\begin{itemize}
			\item Détecter les points de la classe majoritaire les plus proches aux points de la classe minoritaire
			\item Supprimer ces points
			\item \expword{imblearn.under\_sampling.TomekLinks}
		\end{itemize}
		\item \keyword{I'm too lazy to present more methods! :)}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Données déséquilibrées : Sur-échantillonnage}
	
	\begin{itemize}
		\item Ajouter des échantillons de la classe minoritaire (oversampling)
		\item \optword{Duplication aléatoire}
		\begin{itemize}
			\item \expword{imblearn.over\_sampling.RandomOverSampler}
		\end{itemize}
		\item \optword{SMOTE (Synthetic Minority Over-sampling Technique)}
		\begin{itemize}
			\item Chercher les K voisins les plus proches de chaque point de la classe minoritaire
			\item Définir un nouveau point entre ce point et un de ces voisins
			\item \expword{imblearn.over\_sampling.SMOTE}
		\end{itemize}
		\item \optword{ADASYN (Adaptive Synthetic Sampling)}
		\begin{itemize}
			\item Comme \keyword{SMOTE}
			\item La méthode favorise les points dans des espaces non homogènes
			\item \expword{imblearn.over\_sampling.ADASYN}
		\end{itemize}
		\item \keyword{Still lazy}
	\end{itemize}
	
\end{frame}

\subsection{Fractionnement des données}

\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Fractionnement des données}
	
	\begin{itemize}
		\item Division des données
		\begin{itemize}
			\item \optword{Entrainement} : une majorité des échantillons (70-80\%)
			\item \optword{Test} : une minorité des échantillons (30-20\%)
			\item \optword{Validation} : une minorité des échantillons pour régler les hyper-paramètres (20\% à partir de l'entrainement)
		\end{itemize}
		\item Condition sur la division
		\begin{itemize}
			\item Les données de test sont suffisantes pour avoir des résultats significatifs.
			\item Les données de test sont représentatives. Il ne faut pas prendre un ensemble avec des caractéristiques différentes de celles des données d'entrainement.
			\item Si le problème est une prédiction du futur à base du passé, il faut diviser le dataset tel que le test suit l'entrainement
			\item Pour ne pas perdre les données d'entrainement, utiliser la validation croisée
		\end{itemize}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Fractionnement des données : Données et apprentissage}
	
	\begin{itemize}
		\item \optword{Sous-apprentissage (Underfitting)}
		\begin{itemize}
			\item Le modèle n'a pas pris de temps pour généraliser sur les données d'entrainement
			\item Peu de données d'entrainement
			\item Les données d'entrainement ne sont pas représentatives 
		\end{itemize}
		\item \optword{Sur-apprentissage (Overfitting)}
		\begin{itemize}
			\item Le modèle a appris un apprentissage ``par cœur" des données
			\item Il existe du bruit dans les données d'entrainement
			\item Les données de test ne sont pas représentatives. 
		\end{itemize}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Fractionnement des données : Échantillonnage stratifié}
	
	\begin{itemize}
		\item Division aléatoire des données
		\begin{itemize}
			\item Les données de test peuvent ne pas contenir des classes
			\item Les données de test peuvent ne pas être proportionnelles à celles d'entrainement
		\end{itemize}
		\item Étapes
		\begin{itemize}
			\item Séparer les données selon leurs classes
			\item Prendre des échantillons aléatoirement de chaque classe pour former le dataset de test
			\item On peut calculer les proportions originales de chaque classe dans les données et extraire des échantillons selon ses proportions
		\end{itemize}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Fractionnement des données : Validation croisée}
	
	\begin{figure}
		\centering
		\hgraphpage[.5\textwidth]{grid_search_workflow.png}
		\caption{Workflow de l'apprentissage automatique avec validation croisée \cite{2020-sklearn-man}}
	\end{figure}
	
\end{frame}


\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Fractionnement des données : Validation croisée (K-Folds)}
	
	\begin{figure}
		\centering
		\hgraphpage[.6\textwidth]{grid_search_cross_validation.png}
		\caption{Illustration de la validation croisée K-Folds \cite{2020-sklearn-man}}
	\end{figure}
	
\end{frame}

\begin{frame}
	\frametitle{Échantillonnage et fractionnement des données}
	\framesubtitle{Un peu d'humour}
	
		\begin{center}
			\vgraphpage{humour-fractionnement.jpeg}
			\vgraphpage{humour-traintest.jpg}
		\end{center}
	
\end{frame}

\section{Évaluation des modèles}

%\begin{frame}
%	\frametitle{Évaluation des modèles}
%	
%\end{frame}

\subsection{Classement}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Classement : Matrice de confusion}
	
	\begin{tabular}{|c|c|c|c|}
		\cline{3-4}
		\multicolumn{2}{c|}{}& \multicolumn{2}{c|}{Classes réelles} \\
		\cline{3-4}
		\multicolumn{2}{c|}{}& Positive & Négative \\
		\hline
		\multirow{2}{*}{Prédiction} & Positive & vrai positif (TP) & faux positif (FP) \\
		\cline{2-4}
		& Négative & faux négatif (FN) & vrai négatif (TN) \\
		\hline
	\end{tabular}

	\begin{itemize}
		\item \optword{Vrai positif (True positive)} : Le modèle prédit correctement la classe positive.
		\item \optword{Vrai négatif (True negative)} : Le modèle prédit correctement la classe négative.
		\item \optword{Faux positif (False positive)} : Le modèle prédit incorrectement la classe positive.
		\item \optword{Faux négatif (False negative)} : Le modèle prédit incorrectement la classe négative.
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Classement : Justesse (Accuracy)}
	
	\[Accuracy = \frac{TP + TN}{TP + FP + FN + TN}\]
	
	\begin{tabular}{|c|c|c|c|}
		\cline{3-4}
		\multicolumn{2}{c|}{}& \multicolumn{2}{c|}{Classes réelles} \\
		\cline{3-4}
		\multicolumn{2}{c|}{}& indésirable & désirable \\
		\hline
		\multirow{2}{*}{Prédiction} & indésirable & 0 & 1 \\
		\cline{2-4}
		& désirable & 3 & 16 \\
		\hline
	\end{tabular}
	
	\begin{itemize}
		\item $Accuracy = \frac{0 + 16}{1 + 1 + 3 + 16} = \frac{16}{20} = 80\%$
		\item La justesse n'est pas une bonne métrique si 
		\begin{itemize}
			\item les classes sont déséquilibrées
			\item on veut avoir la performance du modèle sur la classe positive
		\end{itemize}
		\item \expword{sklearn.metrics.accuracy\_score}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Classement : Rappel, Précision et F1 score}
	
	\vspace{-6pt}
	\[R = \frac{TP}{TP + FN} = \frac{\text{prédicitions positives justes}}{\text{échantillons positifs réels}}\]
	
	\begin{itemize}
		\item La capacité de trouver tous les échantillons positifs par le classificateur
		\item \expword{sklearn.metrics.recall\_score}
	\end{itemize}
	
	\vspace{-6pt}
	\[P = \frac{TP}{TP + FP} = \frac{\text{prédicitions positives justes}}{\text{prédictions positives}}\]
	
	\begin{itemize}
		\item La capacité de ne pas marquer des échantillons négatifs comme positifs par le classificateur
		\item \expword{sklearn.metrics.precision\_score}
	\end{itemize}
	
	\vspace{-6pt}
	\[F1 = \frac{2 P R}{P + R}\]
	
	\begin{itemize}
		\item Moyenne harmonique entre P et R
		\item \expword{sklearn.metrics.f1\_score}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Classement : R, P et F1 (multi-classes)}
	
	\begin{itemize}
		\item $\hat{y}$ : l'ensemble des prédictions, $y$ : l'ensemble des étiquettes justes
		\item $L$ : l'ensemble des étiquettes (classes)
		\item $S$ : l'ensemble des échantillons
		\item $M$ : la métrique qui peut être $R$, $P$ ou $F1$
	\end{itemize}


\begin{center}
	\SetTblrInner{rowsep=0pt,colsep=1pt}
	\begin{tblr}{
			colspec = {p{0.3\textwidth}p{0.5\textwidth}},
			row{odd} = {lightblue, font=\small},
			row{even} = {lightyellow, font=\small},
			row{1} = {darkblue, font=\bfseries},
		}
		\textcolor{white}{Moyenne} & \textcolor{white}{Formule de calcul} \\
		micro (Précision) & \vspace{-6pt}\[\frac{\sum_{l \in L} TP_l}{\sum_{l \in L} (TP_l + FP_l)}\]\vspace{-6pt} \\
		macro & \vspace{-6pt}\[\frac{1}{|L|} \sum_{l \in L} M(y_l, \hat{y}_l)\]\vspace{-6pt}\\
		pondérée & \vspace{-6pt}\[\frac{1}{\sum_{l \in L} |\hat{y}_l|} \sum_{l \in L} |\hat{y}_l| M(y_l, \hat{y}_l)\]\vspace{-6pt} \\
	\end{tblr}
\end{center}
	
	
\end{frame}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Classement : Corrélation de matthews}
	
	\[CCM = \frac{TP \times TN - FP \times FN}{\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}\]
	\begin{itemize}
		\item Le coefficient peut être entre \textbf{-1} et \textbf{+1}
		\begin{itemize}
			\item -1 : les prédictions sont totalement irronnées.
			\item 0 : la performance du modèle est comparable avec un système aléatoire (random).
			\item +1 : les prédictions sont parfaites.
		\end{itemize}
		\item \expword{sklearn.metrics.matthews\_corrcoef}
	\end{itemize}
	
	
\end{frame}

\subsection{Régression}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Régression : Erreur quadratique moyenne}
	
	\[MSE(\hat{y}, y) = \mathbb{E}(y - \hat{y})^2 =  \frac{1}{|S|} \sum_{i=1}^{|S|} (y_i - \hat{y}_i)^2\]
	
	\begin{itemize}
		\item \optword{Mean Squared Error}
		\item Punir le modèle lorsqu'il y a des grandes erreurs (magnifier les grandes erreurs)
		\item En réalité, calcule l'erreur carrée
		\item \expword{sklearn.metrics.mean\_squared\_error}
		\item Pour avoir l'erreur, on peut appliquer une racine carrée
		\item $RMSE(\hat{y}, y) = \sqrt{MSE(\hat{y}, y)}$
		\item \optword{Root Mean Squared Error}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Régression : Erreur absolue moyenne}
	
	\[MAE(\hat{y}, y) = \mathbb{E}|y - \hat{y}| =  \frac{1}{|S|} \sum_{i=1}^{|S|} |y_i - \hat{y}_i|\]
	
	\begin{itemize}
		\item \optword{Mean Absolute Error}
		\item Considère les petites erreurs et les grandes erreurs de la même magnitude
		\item \expword{sklearn.metrics.mean\_absolute\_error}
	\end{itemize}
	
\end{frame}

\subsection{Regroupement}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Regroupement : Indice de Rand}
	
	\[RI(\hat{y}, y) = \frac{|\hat{y} \bigcap y|}{|y|}\]
	
	\begin{itemize}
		\item Il faut avoir un corpus annoté
		\item \expword{sklearn.metrics.rand\_score}
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\frametitle{Regroupement : Silhouette}
	
		\begin{itemize}
		\item $C$ l'ensemble des clusters
		\item $a_i$ est la distance moyenne du point $i$ avec les points du même cluster
		\item $b_i$ est la distance moyenne du point $i$ avec les points du cluster le plus proche
		\item \expword{sklearn.metrics.silhouette\_score}
	\end{itemize}
	
	\[a_i = \frac{1}{|C_k| - 1} \sum_{j \in C_k,\; i \ne j} d(i, j) / \; i \in C_k\]
	\[b_i = \min_{i \notin C_k} \frac{1}{|C_k|} \sum_{j \in C_k} d(i, j)\]
	\[s_i = \frac{b_i - a_i}{max(a_i, b_i)}\]
	
	
\end{frame}

\begin{frame}
	\frametitle{Évaluation des modèles}
	\framesubtitle{Un peu d'humour}
	
	\begin{center}
		\vgraphpage{humour-eval1.png}
		\vgraphpage{humour-eval2.jpg}
	\end{center}
	
\end{frame}

\insertbibliography{ML-preparation}{*}

\end{document}



